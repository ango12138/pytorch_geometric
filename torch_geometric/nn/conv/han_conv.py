from typing import Union, Dict, Optional, List
from torch_geometric.typing import NodeType, EdgeType, Metadata

from collections import defaultdict
import torch
from torch import Tensor
import torch.nn.functional as F
from torch.nn import Parameter
from torch_sparse import SparseTensor
from torch_geometric.nn.dense import Linear
from torch_geometric.utils import softmax
from torch_geometric.nn.conv import MessagePassing
from torch_geometric.nn.inits import glorot, reset


def group(xs: List[Tensor], aggr: Optional[str]) -> Optional[Tensor]:
    if len(xs) == 0:
        return None
    elif aggr is None:
        return torch.stack(xs, dim=1)
    elif len(xs) == 1:
        return xs[0]
    else:
        out = torch.stack(xs, dim=0)
        out = getattr(torch, aggr)(out, dim=0)
        out = out[0] if isinstance(out, tuple) else out
        return out


class HANConv(MessagePassing):
    r"""
    The Heterogenous Graph Attention Operator from the
    `"Heterogenous Graph Attention Network"
    <https://arxiv.org/pdf/1903.07293.pdf>` paper
    Args:
        in_channels (int or Dict[str, int]): Size of each input sample of every
            node type, or :obj:`-1` to derive the size from the first input(s)
            to the forward method.
        out_channels (int): Size of each output sample.
        metadata (Tuple[List[str], List[Tuple[str, str, str]]]): The metadata
            of the heterogeneous graph, *i.e.* its node and edge types given
            by a list of strings and a list of string triplets, respectively.
            See :meth:`torch_geometric.data.HeteroData.metadata` for more
            information.
        heads (int, optional): Number of multi-head-attentions.
            (default: :obj:`1`)
        group (string, optional): The aggregation scheme to use for grouping
            node embeddings generated by different relations.
            (:obj:`"sum"`, :obj:`"mean"`, :obj:`"min"`, :obj:`"max"`).
            (default: :obj:`"sum"`)
        **kwargs (optional): Additional arguments of
            :class:`torch_geometric.nn.conv.MessagePassing`.
    """
    def __init__(
        self,
        in_channels: Union[int, Dict[str, int]],
        out_channels: int,
        metadata: Metadata,
        heads: int = 1,
        negative_slope=0.2,
        group: str = "sum",
        **kwargs,
    ):
        super().__init__(aggr='add', node_dim=0, **kwargs)
        if not isinstance(in_channels, dict):
            in_channels = {node_type: in_channels for node_type in metadata[0]}
        self.rel_types = []
        self.group = group
        self.heads = heads
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.negative_slope = negative_slope
        self.metadata = metadata
        self.proj = torch.nn.ModuleDict()
        self.src_rel = torch.nn.ParameterDict()
        self.dst_rel = torch.nn.ParameterDict()
        for node_type in metadata[0]:
            self.proj[node_type] = Linear(in_channels[node_type], out_channels)
        dim = out_channels // heads
        for metapath in metadata[1]:
            self.rel_types.append('__'.join(metapath))
            src, rel, dst = metapath
            self.src_rel['__'.join(metapath)] = Parameter(
                torch.Tensor(1, heads, dim))
            self.dst_rel['__'.join(metapath)] = Parameter(
                torch.Tensor(1, heads, dim))
        self.semantic_prj = Linear(out_channels, out_channels)
        self.semantic_attn = Parameter(torch.Tensor(out_channels))

    def reset_parameters(self):
        reset(self.proj)
        glorot(self.a_rel)
        reset(self.semantic_proj)
        glorot(self.semantic_attn)

    def forward(
        self,
        x_dict: Dict[NodeType, Tensor],
        edge_index_dict: Union[Dict[EdgeType, Tensor], Dict[EdgeType,
                                                            SparseTensor]],
    ) -> Dict[NodeType, Optional[Tensor]]:
        r"""
        Args:
            x_dict (Dict[str, Tensor]): A dictionary holding input node
                features  for each individual node type.
            edge_index_dict: (Dict[str, Union[Tensor, SparseTensor]]): A
                dictionary holding graph connectivity information for each
                individual edge type, either as a :obj:`torch.LongTensor` of
                shape :obj:`[2, num_edges]` or a
                :obj:`torch_sparse.SparseTensor`.

        :rtype: :obj:`Dict[str, Optional[Tensor]]` - The ouput node embeddings
            for each node type.
            In case a node type does not receive any message, its output will
            be set to :obj:`None`.
        """
        H, D = self.heads, self.out_channels // self.heads
        x_node_dict = dict()
        # Iterate over node types
        for node_type, x_node in x_dict.items():
            x_node_dict[node_type] = self.proj[node_type](x_node).view(
                -1, H, D)
        # Create metapath message dictionary
        msg_dict = dict()

        # Iterate over edge types(metapaths)
        for edge_type, edge_index in edge_index_dict.items():
            src_type, rel, dst_type = edge_type
            src_rel = self.src_rel['__'.join(edge_type)]
            dst_rel = self.dst_rel['__'.join(edge_type)]
            x_src = x_node_dict[src_type]
            x_dst = x_node_dict[dst_type]
            # propagate_type: (x_src_j: Tensor, src_rel: Tensor,
            # x_dst_i: Tensor, dst_rel: Tensor)
            out = self.propagate(edge_index, x_src=x_src, src_rel=src_rel,
                                 x_dst=x_dst, dst_rel=dst_rel,
                                 size=(x_src.shape[0], x_dst.shape[0]))
            # applying non-linearity to semantic specific node embedding
            out = F.relu(out)
            msg_dict['__'.join(edge_type)] = out

        # compute attention across semantic
        semattn_scores = []
        for rel_type in self.rel_types:
            x = msg_dict[rel_type]
            x = torch.tanh(self.semantic_prj(x)).mean(0)
            semattn_scores.append((self.semantic_attn * x).sum())
        semattn_scores = F.softmax(torch.tensor(semattn_scores), dim=-1)

        # creating the out dictionary
        out_dict = defaultdict(lambda: [])
        # iterate through all rel types
        for i, rel_type in enumerate(self.rel_types):
            dst_type = rel_type.split('__')[-1]
            out_dict[dst_type].append(semattn_scores[i] * msg_dict[rel_type])

        # iterate through all node types and
        # aggregate the information from all semantic types
        for node_type, outs in out_dict.items():
            out = group(outs, self.group)

            if out is None:
                out_dict[node_type] = None
                continue
            out_dict[node_type] = out

        return out_dict

    def message(self, x_src_j: Tensor, src_rel: Tensor, x_dst_i: Tensor,
                dst_rel: Tensor, index: Tensor, ptr: Optional[Tensor],
                size_i: Optional[int]) -> Tensor:

        alpha_j = (x_src_j * src_rel).sum(dim=-1)
        alpha_i = (x_dst_i * dst_rel).sum(dim=-1)
        alpha = alpha_j + alpha_i
        alpha = F.leaky_relu(alpha, self.negative_slope)
        alpha = softmax(alpha, index, ptr, size_i)
        out = x_dst_i * alpha.view(-1, self.heads, 1)
        return out.view(-1, self.out_channels)

    def __repr__(self) -> str:
        return (f'{self.__class__.__name__}({self.out_channels}, '
                f'heads={self.heads})')
